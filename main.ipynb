{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liangchingyun/A-Convolution-Module-For-Variable-Input-Channels/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR7mAkCyFIUK",
        "outputId": "d7d358ab-d0b8-401b-fb4e-0414472010be"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/liangchingyun/A-Convolution-Module-For-Variable-Input-Channels.git\n",
        "%cd A-Convolution-Module-For-Variable-Input-Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hnvhtd-v6u3n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import argparse\n",
        "from typing import Callable, Optional, Type, Union, List\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e9PJTFJ_0ull"
      },
      "outputs": [],
      "source": [
        "class attention2d(nn.Module):\n",
        "    def __init__(self, in_planes, ratios, K, temperature, init_weight=True):\n",
        "        super(attention2d, self).__init__()\n",
        "        assert temperature%3==1\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        if in_planes!=3:\n",
        "            hidden_planes = int(in_planes*ratios)+1\n",
        "        else:\n",
        "            hidden_planes = K\n",
        "        self.fc1 = nn.Conv2d(in_planes, hidden_planes, 1, bias=False)\n",
        "        # self.bn = nn.BatchNorm2d(hidden_planes)\n",
        "        self.fc2 = nn.Conv2d(hidden_planes, K, 1, bias=True)\n",
        "        self.temperature = temperature\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            if isinstance(m ,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def updata_temperature(self):\n",
        "        if self.temperature!=1:\n",
        "            self.temperature -=3\n",
        "            print('Change temperature to:', str(self.temperature))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x).view(x.size(0), -1)\n",
        "        return F.softmax(x/self.temperature, 1)\n",
        "\n",
        "class Dynamic_conv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=34, init_weight=True):\n",
        "        super(Dynamic_conv2d, self).__init__()\n",
        "        assert in_planes%groups==0\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "        self.bias = bias\n",
        "        self.K = K\n",
        "        self.attention = attention2d(in_planes, ratio, K, temperature)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(K, out_planes, in_planes//groups, kernel_size, kernel_size), requires_grad=True)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(K, out_planes))\n",
        "        else:\n",
        "            self.bias = None\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "        #TODO 初始化\n",
        "    def _initialize_weights(self):\n",
        "        for i in range(self.K):\n",
        "            nn.init.kaiming_uniform_(self.weight[i])\n",
        "\n",
        "\n",
        "    def update_temperature(self):\n",
        "        self.attention.updata_temperature()\n",
        "\n",
        "    def forward(self, x):#将batch视作维度变量，进行组卷积，因为组卷积的权重是不同的，动态卷积的权重也是不同的\n",
        "        softmax_attention = self.attention(x)\n",
        "        batch_size, in_planes, height, width = x.size()\n",
        "        x = x.view(1, -1, height, width)# 变化成一个维度进行组卷积\n",
        "        weight = self.weight.view(self.K, -1)\n",
        "\n",
        "        # 动态卷积的权重的生成， 生成的是batch_size个卷积参数（每个参数不同）\n",
        "        aggregate_weight = torch.mm(softmax_attention, weight).view(batch_size*self.out_planes, self.in_planes//self.groups, self.kernel_size, self.kernel_size)\n",
        "        if self.bias is not None:\n",
        "            aggregate_bias = torch.mm(softmax_attention, self.bias).view(-1)\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups*batch_size)\n",
        "        else:\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups * batch_size)\n",
        "\n",
        "        output = output.view(batch_size, self.out_planes, output.size(-2), output.size(-1))\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPjZlTOKhm8D"
      },
      "source": [
        "ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "__all__ = [\"ResNet\", \"resnet18\"]\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
        "            )\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck) and m.bn3.weight is not None:\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIaYozpvDKHZ"
      },
      "source": [
        "DY-ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "CHkarCY7DZh6"
      },
      "outputs": [],
      "source": [
        "\n",
        "__all__ = ['DY_ResNet', 'dy_resnet18']\n",
        "\n",
        "def dy_conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def dy_conv1x1(in_planes, out_planes, stride=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False,)\n",
        "\n",
        "class DY_BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(DY_BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = dy_conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = dy_conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class DY_ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(DY_ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, DY_BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "\n",
        "    def update_temperature(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Dynamic_conv2d):\n",
        "                m.update_temperature()\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                dy_conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "def _dyresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = DY_ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def dy_resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _dyresnet('resnet18', DY_BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4h4gxdwr6cX"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_3tOpo0OcVm",
        "outputId": "30314526-c899-41c9-f75c-22e47d96de96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=256, test_batch_size=20, epochs=100, lr=0.1, momentum=0.9, weight_decay=0.0001, net_name='resnet18', channel='RGB', f=None, device='cuda:0')\n",
            "Train Epoch: 1, loss 3.384860, acc 0.1211"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/littlefish/miniconda3/envs/cnn-classifier/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val set: average loss: 3.1624, accuracy 17.1111\n",
            "Train Epoch: 2, loss 2.783148, acc 0.2250Val set: average loss: 2.8977, accuracy 20.2222\n",
            "Train Epoch: 3, loss 2.347575, acc 0.3233Val set: average loss: 2.6389, accuracy 26.4444\n",
            "Train Epoch: 4, loss 2.031905, acc 0.4035Val set: average loss: 2.4415, accuracy 33.5556\n",
            "Train Epoch: 5, loss 1.776630, acc 0.4662Val set: average loss: 1.8399, accuracy 44.6667\n",
            "Train Epoch: 6, loss 1.587248, acc 0.5168Val set: average loss: 2.0370, accuracy 41.5556\n"
          ]
        }
      ],
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='dynamic convolution')\n",
        "parser.add_argument('--batch-size', type=int, default=256)\n",
        "parser.add_argument('--test-batch-size', type=int, default=20)\n",
        "parser.add_argument('--epochs', type=int, default=100)\n",
        "parser.add_argument('--lr', type=float, default=0.1, )\n",
        "parser.add_argument('--momentum', type=float, default=0.9)\n",
        "parser.add_argument('--weight-decay', type=float, default=1e-4)\n",
        "parser.add_argument('--net-name', default='resnet18')\n",
        "parser.add_argument('--channel', default='RGB')\n",
        "\n",
        "parser.add_argument('-f')\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "numclasses=50\n",
        "\n",
        "\n",
        "def select_channels(image, channels):\n",
        "    if channels == 'R':\n",
        "        return image[0, :, :].unsqueeze(0)  # 只選R通道\n",
        "    elif channels == 'G':\n",
        "        return image[1, :, :].unsqueeze(0)  # 只選G通道\n",
        "    elif channels == 'B':\n",
        "        return image[2, :, :].unsqueeze(0)  # 只選B通道\n",
        "    elif channels == 'RG':\n",
        "        return image[:2, :, :]  # 選RG通道\n",
        "    elif channels == 'GB':\n",
        "        return image[1:, :, :]  # 選GB通道\n",
        "    elif channels == 'RB':\n",
        "        return image[[0, 2], :, :]  # 選RB通道\n",
        "    else:  # 默認RGB\n",
        "        return image\n",
        "\n",
        "def get_transforms(channel):\n",
        "    transform_list = [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: select_channels(x, channel)),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406][:len(channel)], std=[0.229, 0.224, 0.225][:len(channel)])]\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "transform = get_transforms(args.channel)\n",
        "\n",
        "# load dataset\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root='val', transform=transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "if args.net_name=='dy_resnet18':\n",
        "    model = dy_resnet18(num_classes=numclasses)\n",
        "else:\n",
        "    model = resnet18(num_classes=numclasses)\n",
        "\n",
        "model.to(args.device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "print(str(args))\n",
        "\n",
        "def adjust_lr(optimizer, epoch):\n",
        "    if epoch in [30, 60, 90]: #[args.epochs*0.5, args.epochs*0.75, args.epochs*0.85]\n",
        "        for p in optimizer.param_groups:\n",
        "            p['lr'] *= 0.1\n",
        "            lr = p['lr']\n",
        "        print('Change lr:'+str(lr))\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    adjust_lr(optimizer, epoch)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data, target = data.to(args.device), target.to(args.device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    \n",
        "    \n",
        "    avg_loss /= len(train_loader)\n",
        "    train_acc = train_acc / len(train_loader.dataset)\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    \n",
        "    print('Train Epoch: {}, loss {:.6f}, acc {:.4f}'.format(epoch, avg_loss, train_acc), end='')\n",
        "    if args.net_name.startswith('dy'):\n",
        "        model.update_temperature()\n",
        "\n",
        "\n",
        "def val(epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in val_loader:\n",
        "            data, label = data.to(args.device), label.to(args.device)\n",
        "            output = model(data)\n",
        "            val_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    val_loss/=len(val_loader.dataset)\n",
        "    correct = int(correct)\n",
        "    val_losses.append(val_loss)\n",
        "    val_acc = correct / len(val_loader.dataset)\n",
        "    val_accuracies.append(val_acc)\n",
        "    print('Val set: average loss: {:.4f}, accuracy {:.4f}'.format(val_loss, 100. * val_acc))\n",
        "    return val_acc\n",
        "\n",
        "\n",
        "best_val_acc=0.\n",
        "for i in range(args.epochs):\n",
        "    train(i+1)\n",
        "    temp_acc = val(i+1)\n",
        "    if temp_acc>best_val_acc:\n",
        "        best_val_acc = temp_acc\n",
        "print('Best Val acc{}'.format(best_val_acc))\n",
        "\n",
        "# Test\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.\n",
        "correct=0.\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        data, label = data.to(args.device), label.to(args.device)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "        pred =  output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "test_loss/=len(test_loader.dataset)\n",
        "correct = int(correct)\n",
        "print(f'Test Accuracy: {correct/len(test_loader.dataset):.4f}')\n",
        "\n",
        "# Costs\n",
        "stat(model, (len(args.channel), 224, 224))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def params_count(model):\n",
        "    return np.sum([p.numel() for p in model.parameters()]).item()\n",
        "\n",
        "print('#PARAMS: ',params_count(model))\n",
        "\n",
        "train_losses = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in train_losses]\n",
        "val_losses = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in val_losses]\n",
        "train_accuracies = [acc.cpu().item() if torch.is_tensor(acc) else acc for acc in train_accuracies]\n",
        "val_accuracies = [acc.cpu().item() / 100 if torch.is_tensor(acc) else acc / 100 for acc in val_accuracies]\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, args.epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, args.epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 绘制训练和验证的准确度曲线\n",
        "plt.figure()\n",
        "plt.plot(range(1, args.epochs + 1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, args.epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "commit e56c9c974e60d62d2d513a6cf2a3df416afa3f4a\n",
            "Author: Chen-Yang Yu <adrianyu890317@gmail.com>\n",
            "Date:   Wed Jun 5 14:29:47 2024 +0800\n",
            "\n",
            "    6/5\n",
            "\n",
            "commit ae7c36afc3d41cef572218be036963eae7a92a52\n",
            "Author: Chen-Yang Yu <adrianyu890317@gmail.com>\n",
            "Date:   Tue Jun 4 17:46:43 2024 +0800\n",
            "\n",
            "    6/4\n",
            "\n",
            "commit ad2e4a71034198b3a71a6740cac17166ec5d2364\n",
            "Author: Chen-Yang Yu <adrianyu890317@gmail.com>\n",
            "Date:   Tue Jun 4 16:10:07 2024 +0800\n",
            "\n",
            "    6/4\n"
          ]
        }
      ],
      "source": [
        "! git log -3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
