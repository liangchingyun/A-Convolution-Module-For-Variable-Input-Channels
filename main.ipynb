{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liangchingyun/A-Convolution-Module-For-Variable-Input-Channels/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR7mAkCyFIUK",
        "outputId": "9a8dc89b-e7cb-4ba1-928a-8b9a706b1a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'A-Convolution-Module-For-Variable-Input-Channels'...\n",
            "remote: Enumerating objects: 64293, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 64293 (delta 10), reused 5 (delta 1), pack-reused 64272\u001b[K\n",
            "Receiving objects: 100% (64293/64293), 1.35 GiB | 29.30 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Updating files: 100% (64229/64229), done.\n",
            "/content/A-Convolution-Module-For-Variable-Input-Channels\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/liangchingyun/A-Convolution-Module-For-Variable-Input-Channels.git\n",
        "%cd A-Convolution-Module-For-Variable-Input-Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnvhtd-v6u3n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import argparse\n",
        "from torchstat import stat\n",
        "# from .utils import load_state_dict_from_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9PJTFJ_0ull"
      },
      "outputs": [],
      "source": [
        "class attention2d(nn.Module):\n",
        "    def __init__(self, in_planes, ratios, K, temperature, init_weight=True):\n",
        "        super(attention2d, self).__init__()\n",
        "        assert temperature%3==1\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        if in_planes!=3:\n",
        "            hidden_planes = int(in_planes*ratios)+1\n",
        "        else:\n",
        "            hidden_planes = K\n",
        "        self.fc1 = nn.Conv2d(in_planes, hidden_planes, 1, bias=False)\n",
        "        # self.bn = nn.BatchNorm2d(hidden_planes)\n",
        "        self.fc2 = nn.Conv2d(hidden_planes, K, 1, bias=True)\n",
        "        self.temperature = temperature\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            if isinstance(m ,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def updata_temperature(self):\n",
        "        if self.temperature!=1:\n",
        "            self.temperature -=3\n",
        "            print('Change temperature to:', str(self.temperature))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x).view(x.size(0), -1)\n",
        "        return F.softmax(x/self.temperature, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTzKdrTZAMED"
      },
      "outputs": [],
      "source": [
        "class Dynamic_conv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=34, init_weight=True):\n",
        "        super(Dynamic_conv2d, self).__init__()\n",
        "        assert in_planes%groups==0\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "        self.bias = bias\n",
        "        self.K = K\n",
        "        self.attention = attention2d(in_planes, ratio, K, temperature)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(K, out_planes, in_planes//groups, kernel_size, kernel_size), requires_grad=True)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(K, out_planes))\n",
        "        else:\n",
        "            self.bias = None\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "        #TODO 初始化\n",
        "    def _initialize_weights(self):\n",
        "        for i in range(self.K):\n",
        "            nn.init.kaiming_uniform_(self.weight[i])\n",
        "\n",
        "\n",
        "    def update_temperature(self):\n",
        "        self.attention.updata_temperature()\n",
        "\n",
        "    def forward(self, x):#将batch视作维度变量，进行组卷积，因为组卷积的权重是不同的，动态卷积的权重也是不同的\n",
        "        softmax_attention = self.attention(x)\n",
        "        batch_size, in_planes, height, width = x.size()\n",
        "        x = x.view(1, -1, height, width)# 变化成一个维度进行组卷积\n",
        "        weight = self.weight.view(self.K, -1)\n",
        "\n",
        "        # 动态卷积的权重的生成， 生成的是batch_size个卷积参数（每个参数不同）\n",
        "        aggregate_weight = torch.mm(softmax_attention, weight).view(batch_size*self.out_planes, self.in_planes//self.groups, self.kernel_size, self.kernel_size)\n",
        "        if self.bias is not None:\n",
        "            aggregate_bias = torch.mm(softmax_attention, self.bias).view(-1)\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups*batch_size)\n",
        "        else:\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups * batch_size)\n",
        "\n",
        "        output = output.view(batch_size, self.out_planes, output.size(-2), output.size(-1))\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet"
      ],
      "metadata": {
        "id": "UPjZlTOKhm8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "__all__ = [\"ResNet\", \"resnet18\"]\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        _log_api_usage_once(self)\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
        "            )\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck) and m.bn3.weight is not None:\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        planes: int,\n",
        "        blocks: int,\n",
        "        stride: int = 1,\n",
        "        dilate: bool = False,\n",
        "    ) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wm1WmuS4hsfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIaYozpvDKHZ"
      },
      "source": [
        "DY-ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHkarCY7DZh6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "__all__ = ['DY_ResNet', 'dy_resnet18']\n",
        "\n",
        "def dy_conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def dy_conv1x1(in_planes, out_planes, stride=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False,)\n",
        "\n",
        "\n",
        "class DY_BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(DY_BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = dy_conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = dy_conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class DY_ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(DY_ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, DY_BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "\n",
        "    def update_temperature(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Dynamic_conv2d):\n",
        "                m.update_temperature()\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                dy_conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _dyresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = DY_ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def dy_resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _dyresnet('resnet18', DY_BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4h4gxdwr6cX"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "D_3tOpo0OcVm",
        "outputId": "d069c484-84ba-4403-f874-64841da9189e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-771fd8721c54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='dynamic convolution')\n",
        "parser.add_argument('--batch-size', type=int, default=128)\n",
        "parser.add_argument('--test-batch-size', type=int, default=20)\n",
        "parser.add_argument('--epochs', type=int, default=160)\n",
        "parser.add_argument('--lr', type=float, default=0.1, )\n",
        "parser.add_argument('--momentum', type=float, default=0.9)\n",
        "parser.add_argument('--weight-decay', type=float, default=1e-4)\n",
        "parser.add_argument('--net-name', default='resnet18')\n",
        "parser.add_argument('--channel', default='RGB')\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "numclasses=50\n",
        "\n",
        "def select_channels(image, channels):\n",
        "    if channels == 'R':\n",
        "        return image[0, :, :].unsqueeze(0)  # 只選R通道\n",
        "    elif channels == 'G':\n",
        "        return image[1, :, :].unsqueeze(0)  # 只選G通道\n",
        "    elif channels == 'B':\n",
        "        return image[2, :, :].unsqueeze(0)  # 只選B通道\n",
        "    elif channels == 'RG':\n",
        "        return image[:2, :, :]  # 選RG通道\n",
        "    elif channels == 'GB':\n",
        "        return image[1:, :, :]  # 選GB通道\n",
        "    elif channels == 'RB':\n",
        "        return image[[0, 2], :, :]  # 選RB通道\n",
        "    else:  # 默認RGB\n",
        "        return image\n",
        "\n",
        "def get_transforms(channel):\n",
        "    transform_list = [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: select_channels(x, channel)),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406][:len(channel)],\n",
        "                             std=[0.229, 0.224, 0.225][:len(channel)])\n",
        "    ]\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "transform = get_transforms(args.channel)\n",
        "\n",
        "# load dataset\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root='val', transform=transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "if args.net_name=='dy_resnet18':\n",
        "  model = dy_resnet18(num_classes=numclasses)\n",
        "else:\n",
        "  model = resnet18(num_classes=numclasses)\n",
        "\n",
        "model.to(args.device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "print(str(args))\n",
        "\n",
        "def adjust_lr(optimizer, epoch):\n",
        "    if epoch in [args.epochs*0.5, args.epochs*0.75, args.epochs*0.85]:\n",
        "        for p in optimizer.param_groups:\n",
        "            p['lr'] *= 0.1\n",
        "            lr = p['lr']\n",
        "        print('Change lr:'+str(lr))\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    adjust_lr(optimizer, epoch)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data, target = data.to(args.device), target.to(args.device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(train_loader.dataset)), end='')\n",
        "    if args.net_name.startswith('dy'):\n",
        "        model.update_temperature()\n",
        "\n",
        "\n",
        "def val(epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in val_loader:\n",
        "            data, label = data.to(args.device), label.to(args.device)\n",
        "            output = model(data)\n",
        "            val_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    val_loss/=len(val_loader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Val set:average loss: {:.4f}, accuracy{}'.format(val_loss, 100.*correct/len(val_loader.dataset)))\n",
        "    return correct/len(val_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "best_val_acc=0.\n",
        "for i in range(args.epochs):\n",
        "    train(i+1)\n",
        "    temp_acc = val(i+1)\n",
        "    if temp_acc>best_val_acc:\n",
        "        best_val_acc = temp_acc\n",
        "print('Best Val acc{}'.format(best_val_acc))\n",
        "\n",
        "# Test\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.\n",
        "correct=0.\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        data, label = data.to(args.device), label.to(args.device)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "        pred =  output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "test_loss/=len(test_loader.dataset)\n",
        "correct = int(correct)\n",
        "print(f'Test Accuracy: {correct/len(test_loader.dataset):.4f}')\n",
        "\n",
        "# Costs\n",
        "stat(model, (len(args.channel), 224, 224))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}